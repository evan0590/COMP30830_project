{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library Imports.\n",
    "import operator\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Allows plots to appear directly in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "from patsy import dmatrices\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "import sqlalchemy as sqla\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import csv\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URI='database-comp30830.c2kwpm1jk01q.us-east-1.rds.amazonaws.com'\n",
    "PORT='3306'\n",
    "DB='comp30830_db'\n",
    "PASSWORD='Simple12'\n",
    "USER='admin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql+mysqldb://{}:{}@{}:{}/{}\".format(USER, PASSWORD,\n",
    "                                                              URI, PORT, DB), echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bikes=pd.read_sql_table('live_bike_data', engine)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe of this table\n",
    "bikes.to_csv('allBikes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file into a dataframe.\n",
    "bikes = pd.read_csv('allBikes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather=pd.read_sql_table('live_weather_data', engine)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe of this table\n",
    "weather.to_csv('allWeather.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file into a dataframe.\n",
    "weather = pd.read_csv('allWeather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes['datetime'] = pd.to_datetime(bikes['date'] + ' ' + bikes['time'])\n",
    "weather['datetime'] = pd.to_datetime(weather['date'] + ' ' + weather['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes = bikes.sort_values(by='datetime')\n",
    "weather = weather.sort_values(by='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This can be used as a checkpoint, start from here if you want to run again without having to call from the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge_asof(bikes, weather, left_on=\"datetime\", right_on=\"datetime\",direction=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "full_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrict the dataframe to only those times in which the service is available to users.\n",
    "full_df = full_df.drop(full_df[(full_df.datetime.dt.hour > 0) & (full_df.datetime.dt.hour < 5)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create four each flags representing the stage of the day.\n",
    "morning_start = pd.to_datetime(\"05:00:00\").time()\n",
    "morning_end = pd.to_datetime(\"12:00:00\").time()\n",
    "afternoon_start = pd.to_datetime(\"12:01:00\").time()\n",
    "afternoon_end = pd.to_datetime(\"16:59:00\").time()\n",
    "evening_start = pd.to_datetime(\"17:00:00\").time()\n",
    "evening_end = pd.to_datetime(\"20:00:00\").time()\n",
    "night_start = pd.to_datetime(\"20:01:00\").time()\n",
    "night_end = pd.to_datetime(\"23:59:59\").time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['morning'] = np.where((full_df['datetime'].dt.time > morning_start)\n",
    "                         & (full_df['datetime'].dt.time < morning_end),\n",
    "                         1, 0)\n",
    "\n",
    "full_df['afternoon'] = np.where((full_df['datetime'].dt.time > afternoon_start)\n",
    "                         & (full_df['datetime'].dt.time < afternoon_end),\n",
    "                         1, 0)\n",
    "\n",
    "full_df['evening'] = np.where((full_df['datetime'].dt.time > evening_start)\n",
    "                         & (full_df['datetime'].dt.time < evening_end),\n",
    "                         1, 0)\n",
    "\n",
    "full_df['night'] = np.where((full_df['datetime'].dt.time > night_start)\n",
    "                         & (full_df['datetime'].dt.time < night_end),\n",
    "                         1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace days with numbers\n",
    "full_df[\"day_x\"].replace(['Mon','Tue','Wed','Thu','Fri','Sat','Sun'], [0,1,2,3,4,5,6], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a time of day column, based on the hours of the day.\n",
    "full_df['tod'] = full_df.datetime.dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observe the usage on a given weekday at a particular station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_test_df = full_df.loc[(full_df['ID'] == 84) & (full_df['day_x'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First, plot the observed data\n",
    "weekday_test_df.plot(kind='scatter', x='tod', y='availableBikes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_test_df = full_df.loc[(full_df['ID'] == 84) & (full_df['day_x'] == 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_test_df.plot(kind='scatter', x='tod', y='availableBikes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Observe the usage on a given weekend day at the same station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend_test_df = full_df.loc[(full_df['ID'] == 84) & (full_df['day_x'] == 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, plot the observed data\n",
    "weekend_test_df.plot(kind='scatter', x='tod', y='availableBikes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see two varying patterns for days of the week compared to days of the weekend; therefore two spearate models will be developed- one for Monday to Friday and another for Saturdays and Sundays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clouds\n",
    "full_df[\"number\"].replace([801,802,803,804], 'clouds', inplace=True)\n",
    "\n",
    "#clear\n",
    "full_df[\"number\"].replace([800], 'clear', inplace=True)\n",
    "\n",
    "#Atmosphere\n",
    "full_df[\"number\"].replace([701,711,721,731,741,751,761,762,771,781], 'Atmosphere', inplace=True)\n",
    "\n",
    "#snow\n",
    "full_df[\"number\"].replace([600,601,602,611,612,613,615,616,620,621,622], 'snow', inplace=True)\n",
    "\n",
    "#rain\n",
    "full_df[\"number\"].replace([500,501,502,503,504,511,520,521,522,531], 'rainfall', inplace=True)\n",
    "\n",
    "#drizzle\n",
    "full_df[\"number\"].replace([300,301,302,310,311,312,313,314,321], 'drizzle', inplace=True)\n",
    "\n",
    "#thunderstorm\n",
    "full_df[\"number\"].replace([200,201,202,210,211,212,221,230,231,232], 'thunderstorm', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.drop([\"date_x\",\"time_x\",\"status\", \"epoch\", \"main\",\n",
    "         \"description\",\"icon\", \"tempMin\", \"tempMax\", \"tempFeels\", \"humidity\",\n",
    "         \"pressure\", \"windSpeed\",\"windDeg\",\"sunrise\", \"sunset\",\n",
    "             \"date_y\",\"time_y\", \"day_y\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a flag that indicates whether a day is dry (has zero rain)\n",
    "full_df['dry_day'] = (full_df['rain'] == 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = int(input(\"Please enter a number to predict for either availableBikes - (0) or availableBikeStands - (1): \"))\n",
    "if choice == 0:\n",
    "    full_df = full_df.rename(columns={\"availableBikes\": \"target\"})\n",
    "    full_df.drop([\"availableBikeStands\"], axis=1,inplace=True)    \n",
    "else:\n",
    "    full_df = full_df.rename(columns={\"availableBikeStands\": \"target\"})\n",
    "    full_df.drop([\"availableBikes\"], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_df = full_df.loc[(full_df['day_x'] >= 0) & (full_df['day_x'] <= 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend_df = full_df.loc[(full_df['day_x'] >= 5) & (full_df['day_x'] <= 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station = int(input(\"Please enter station ID: \"))\n",
    "week_or_weekend = int(input(\"Please choose to predict for week - (0) or weekend - (1): \"))\n",
    "# bikes_or_stands = int(input(\"Please choose to predict either availableBikeStands(0) or availableBikes(1): \"))\n",
    "# Constrain df to a single station on a single day\n",
    "if week_or_weekend == 0:\n",
    "    new_df = week_df.loc[(week_df.ID == station)]\n",
    "else:\n",
    "    new_df = weekend_df.loc[(weekend_df.ID == station)]\n",
    "\n",
    "# Constrain df to a single station on a single day\n",
    "# new_df = full_df.loc[(full_df['ID'] == station) & (full_df['day_x'] == day)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping all columns not necessary for predictive model.\n",
    "new_df.drop([\"ID\", \"datetime\"], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new dataframe of this station\n",
    "new_df.to_csv('comp303830_model_multipleLinearRegression.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file into a dataframe.\n",
    "df = pd.read_csv('comp303830_model_multipleLinearRegression.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the average target(availableBikes/availableBikeStands) in our dataset.\n",
    "# We could use this as a very simple baseline prediction model.\n",
    "# A better prediction model should at least improve on this baseline model.\n",
    "round(df.target.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing the data:\n",
    "- Trying to find correlations between continuous data and the target feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='rain', y='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, plot the observed data\n",
    "df.plot(kind='scatter', x='temp', y='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There does not appear to be a clear correlation between the target feature and the continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep these lists for later.\n",
    "## Will be used below.\n",
    "x_list = df.tod.tolist()\n",
    "y_list = df.target.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keep this pandas series for later.\n",
    "## Will be used below.\n",
    "tod_placeholder = df[['tod']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with continuous and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace days with numbers\n",
    "df[\"day_x\"].replace([0,1,2,3,4,5,6], ['Mon','Tue','Wed','Thu','Fri','Sat','Sun'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also do this directly for all categorical features\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input features must exclude the target feature\n",
    "column_names = list(df.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[column_names]\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_first = True removes multi-collinearity\n",
    "add_var = pd.get_dummies(X['tod'], prefix='tod', drop_first=True)\n",
    "# Add all the columns to the model data\n",
    "X = X.join(add_var)\n",
    "# Drop the original column that was expanded\n",
    "X.drop(columns=['tod'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any rows with null values\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X, y)\n",
    "df['predicted'] = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used repeatedly to compute all metrics\n",
    "def printMetrics(testActualVal, predictions):\n",
    "    #classification evaluation measures\n",
    "    print('\\n==============================================================================')\n",
    "    print(\"MAE: \", metrics.mean_absolute_error(testActualVal, predictions))\n",
    "    #print(\"MSE: \", metrics.mean_squared_error(testActualVal, predictions))\n",
    "    print(\"RMSE: \", metrics.mean_squared_error(testActualVal, predictions)**0.5)\n",
    "    print(\"R2: \", metrics.r2_score(testActualVal, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printMetrics(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[['target', 'predicted']].plot(alpha=0.5, figsize=(20, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ref: https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document here on the errors between the predicted and actual values. The model, while not perfect, will suffice for the time being anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pd.Series(model.coef_, index=X.columns)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "np.random.seed(1)\n",
    "err = np.std([model.fit(*resample(X, y)).coef_\n",
    "              for i in range(1000)], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pd.DataFrame({'effect': params.round(0),\n",
    "                    'error': err.round(0)}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ref: https://becominghuman.ai/linear-regression-in-python-with-pandas-scikit-learn-72574a2ec1a5 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Linear regression with nonlinear data: sidebar - we will not actually be using this model due to time constraints faced with implementing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(x_list)\n",
    "y_new = np.asarray(y_list)\n",
    "plt.scatter(x, y_new);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "model.fit(x[:, np.newaxis], y_new)\n",
    "\n",
    "xfit = np.linspace(0, 24, 1000)\n",
    "yfit = model.predict(xfit[:, np.newaxis])\n",
    "\n",
    "plt.scatter(x, y_new)\n",
    "plt.plot(xfit, yfit);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model slope:    \", model.coef_[0])\n",
    "print(\"Model intercept:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming the data to include another axis\n",
    "x = x[:, np.newaxis]\n",
    "y_new = y_new[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(x)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_poly, y_new)\n",
    "y_poly_pred = model.predict(x_poly)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_new,y_poly_pred))\n",
    "r2 = r2_score(y_new,y_poly_pred)\n",
    "print(\"Root Mean Square Error: \", rmse)\n",
    "print(\"Coefficient of Determination (R2): \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y_new, s=10)\n",
    "# sort the values of x before line plot\n",
    "sort_axis = operator.itemgetter(0)\n",
    "sorted_zip = sorted(zip(x,y_poly_pred), key=sort_axis)\n",
    "x, y_poly_pred = zip(*sorted_zip)\n",
    "plt.plot(x, y_poly_pred, color='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore this one more time before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ref: https://jakevdp.github.io/PythonDataScienceHandbook/05.06-linear-regression.html >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "# Take a third (random) data samples as test data, rest as training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "# If we want to get the same train/test split every time we run, we can set the random_state variable to a fixed value\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# print(\"Training data:\\n\", pd.concat([X_train, y_train], axis=1))\n",
    "# print(\"\\nTest data:\\n\", pd.concat([X_test, y_test], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(df.columns)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train on the training sample and test on the test sample.\n",
    "linreg = LinearRegression().fit(X_train, y_train)\n",
    "# Print the weights learned for each feature.\n",
    "#print(linreg_train.coef_)\n",
    "print(\"Features and coeficients:\", list(zip(features, linreg.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted bikes on training set\n",
    "train_predictions = linreg.predict(X_train)\n",
    "# print(\"Actual values of training:\\n\", y_train)\n",
    "# print(\"Predictions on training:\", train_predictions)\n",
    "printMetrics(y_train, train_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted bikes on test set\n",
    "test_predictions = linreg.predict(X_test)\n",
    "# print(\"Actual values of test:\\n\", y_test)\n",
    "# print(\"Predictions on test:\", test_predictions)\n",
    "printMetrics(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation with cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = -cross_val_score(LinearRegression(), X, y, scoring='neg_mean_absolute_error', cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2']\n",
    "scores = cross_validate(LinearRegression(), X, y, scoring=metrics, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(scores.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training with continuous and categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ref: https://stackoverflow.com/questions/34007308/linear-regression-analysis-with-string-categorical-features-variables >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ref: https://towardsdatascience.com/simple-and-multiple-linear-regression-in-python-c928425168f9 >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
